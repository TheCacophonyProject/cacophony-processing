# enter object store and API settings and save as processing.yaml.
# the options listed below should work for the test api-server, set up with the ./run command
---

api_url: "https://api.cacophony.org.nz"
api_user: test-user
api_password: test-password
temp_dir: /tmp/cacophony
# extra-delay before polling the api server again when previous call(s) indicated there were no recordings to process
no_recordings_wait_secs : 30

# restart after x hours
restart_after: 10

trailcam:
  trail_workers: 1
  run_cmd: docker run --env CUDA_VISIBLE_DEVICES=0 --rm     --volume {folder}:/images --env IMG_FILE={basename} --env MD_FILE={outfile}  zaandahl/megadetector:5.0
ir:
  tracking_workers: 0
  analyse_workers: 0
thermal:
    thermal_workers: 2
    tracking_workers: 2
    
    #cache clips that have more than this amount of frames, null is never cache
    cache_clips_bigger_than: 2160
    # classify option allows you to turn off the classifier for test purposes if the classifier is not set up

    # name of container to run
    container_name: classifier
    # used to clear existing docker iamge
    stop_docker: "docker stop {container_name} && docker rm {container_name}"
    # used to run a docker image
    start_docker: "docker run -v {temp_dir}:{temp_dir} --name {container_name} -d {classify_image} /usr/bin/supervisord"
    # to run custom model can addd
    #--mount type=bind,source=\"$(pwd)\"/<classifier config.yaml>,target=/etc/cacophony/classifier.yaml -v <model path>:/etc/cacophony/models/<model>
    # dokcer hub classify image to use
    classify_image: "cacophonyproject/classifier:0.1"
    classify_cmd: "docker exec {container_name} python3 classifyjob.py -o {source} --cache {cache}"
    track_cmd: "docker exec {container_name} python3 extract.py -o {source} --cache {cache}"
    # Can be used to run multiple models, this will save a track tag per model
    # the tags of the first model will be used
    master_tag: "Master"
    wallaby_devices: []

    tagging:
      ignore_tags: ["not"]

      # This is the minimum confidence (for an animal rating) a track should have to be considered a possible animal
      min_confidence: .4

      # This is the minimum confidence a track should have in order to tag as animal
      min_tag_confidence: .8

      # Classifications with a novelty above this value will be ignored for tagging.
      max_tag_novelty: .7

      # This is the minimum difference in confidence between next choice a track should have in order to tag it as the chosen animal
      min_tag_clarity: .2

      # If the same animal has clearly been identified in the video then a reduced clarity is acceptable.
      min_tag_clarity_secondary: .05

      # This is the minimum length of a track.
      min_frames: 3

      # If tracks moves this many pixels in any direction then we shall assume it isn't a false positive
      animal_movement: 50


audio:
    analysis_workers: 2

    # The command will be called to perform analysis on audio recordings (e.g. Cacophony Index, speech detection) using AI models
    analysis_command: 'docker run --rm -v {folder}:/io cacophonyproject/audio-analysis:{tag} /io/"{basename}"'

    analysis_tag: v1.21.1
